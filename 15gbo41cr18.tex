\subsubsection{L1 and L2 Regularization}

The main purpose of regularization term is to reduce model complexity and help to avoid model overfitting problem by panelising the  There are a few types of regularization that are popular, $L_1$ and $L_2$ are among the preferred choices, but the noticeable difference persist between the two. $L_1$ adopts form:

\begin{equation}
   \Omega(\phi) = \frac {1}{2} \sum \parallel \mathcal{w} \parallel^2
\end{equation}

where $\mathcal{w}$ indicates all node weights that are affected by the regularization. 