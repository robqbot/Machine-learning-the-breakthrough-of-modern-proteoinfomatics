\subsubsection{Other Regularization Algorithms}

Dropout~\cite{JMLR:v15:srivastava14a} also known as ensumble method, which was used to be another powerful regularization method, the main reason for its rise to popularity was due to its simplicity yet efficiency and is one of the less computationally expensive regularization option. Dropout is used on fully connected neuron network and has the benefit to capture the randomness in the data structure. Nevertheless, due to recent surgent of modern convolutional architecture, the dropout almost goes out of favour due to its inefficiency in regularizing convolutional models. This arguably is due to generally low number of parameters in convolutional models and the strong correlation between layers; also the more modern adaptation moves away from fully connected model, which limited the application of dropout regularization. 
\par 
Global average pooling method introduced by~\citet{LinCY13} has introduced a final max pooling layer before apply activation function to predict the probability of each class.