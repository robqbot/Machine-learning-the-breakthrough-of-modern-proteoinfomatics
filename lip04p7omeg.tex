\subsubsection{Common Deep Learning Architectures}

\paragraph{Deep neural network - Forwarding}
\subsubsection{Deep neural network - Recurrent}
Recurrent neural networks (RNNs) has reputation in dealing with sequential data, particular in places where data is independent to time steps. 

RNNs models can be trained via back propagation through time~\cite{Goodfellow-et-al-2016}, although some efficiency improved methods have been studied.~\cite{963769,neco.1989,Gomez:2008:ANE:1390681.1390712}

\subsubsection{Convolutional neural network}
Convolutional neural network (CNN) has shown promising implementation in image recognition. The composition of a typical CNN consists several convolution layers and sub-sampling layers in tenden. Each convolution layer is a filter, commonly referred as kernel, which possess a few receptive fields and each is programmable through parameters.  
Convolution neural network has shown far superior performance in image recognition than all other algorithms to date.~\cite{Szegedy_2015}
\par 
Within the realm of convolutional neural networks, there are three