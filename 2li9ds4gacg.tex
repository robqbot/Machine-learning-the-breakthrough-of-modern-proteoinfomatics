\subsection {Learning Methods}
By now, we have defined the objective function, which is a direct measurement of the fitness of our models. The purpose of model training is to make model more accurate in predicting outcomes, which can be achieved by minimising the discrepancy between current model prediction and known data and do it over and over again until satisfaction achieved. 
\par 
Although many aspects of model training can be conceptualized as optimisation problem, there are still some fundamental differences between the two worth to mention. 
\par 
\subsubsection{Model Training and Optimisation}
One of such is model performance $\mathcal{P}(\phi)$, this is more prevalent for large models in production settings. However we have no direct method to optimise $\mathcal{P}(\phi)$, we optimise objective function $\mathcal{Obj}(\phi)$ in hoping by optimise the objective function we also improve model performance $\mathcal{P}(\phi)$ simultaneously, although it is not always the case.
\par 
In addition to improve model performance, another objective of model training in machine learning is to improve generalization capacity by means of reducing generalization error imposed by generalizer term of $\mathcal{Obj}(\phi)$. One of the confronting difficulties in machine learning is that we are not always sure about whether the training dataset is a true representation of reality. Therefore, we almost always minimize an empirical risk problem, where we assume the training data has the same distribution as the reality, therefore a true representation of the problem space. 
\par
Furthermore, $\mathcal{Obj}(\phi)$ in machine learning is not always correspond to loss function in optimisation, particularly in the case where the loss function is discontinuous or i not have differentiable   possible to train efficiently, a proxy is often used in such cases. Surrogate loss is one of such proxy commonly used. 

One advantage of back propagation algorithm is that unlike other method, it can operate on non-normalized input vectors although additional normalization step will generally improve performance. \cite{Buckland:2002} The main theoretical challenge with gradient descent back propagation is that during optimisation, the gradient descent can stuck at local minimum and unable to reach the global minimum, this particularly concerning when error function is non-convex and the error surface is extremely rugged. Nevertheless,~\citet{LeCun_2015} argued this concern is largely theoretical and it is very unlikely to occur in majority practical applications. 