\subsubsection{Objective Function}
The ability to learn (i.e. train) an ANN model to fit for a specific context has been the foundation for the recent resurgence of AI. This learning ability can be represented as an optimization problem, where the optimum network model $f^*$ can be derived from optimising (i.e. minimising) a cost function $\mathcal{C}$ such that $C(f) \geq C(f^*)$, given that the cost of an optimum model is the global minimum. Once the cost function defined, the learning process or model training phase is then simply the process to find such a model $f$ that is $f^*$ or close to be $f^*$. The cost function often referred as loss function in mathematics, econometrics or computational neuroscience; in an optimisation problem, objective function is commonly used interchangeably with minute difference, where object function take both $\pm~C$ and the objective for training is the exercise of minimising or maximising the optimization objective function by changing model parameters $\phi$. In this article, we will use cost function and optimization objective function exchangeably in the context of machine learning.
\\
The implementation of an optimization objective function in machine learning applies the same principle and generally adopts two terms regularization and loss term. The collective efforts to generalize the prediction is summarised as regularization term~\cite{goodfellow_2015}, the loss term describes the measured off-target discrepancy between prediction using model $f(x|\phi)$ (where $x$ is the input vector and $\phi$ is model parameter matrix) and the actual target, which is an evaluator of model fitness. Regularization term also has the main purpose to reduce the complexity of model structure by penalising over complex structure and therefore, reduce concerns over overfitting. A typical optimization objective function can have the form:

\begin{equation}
    \mathcal{Obj}(\mathcal{X},y,\phi) = \mathcal{L}(f(\mathcal{X}|\phi) + \lambda \alpha\omega{R} (\phi) 
\end{equation}

where $\lambda$ is the regularization parameter, $\mathcal{R}$ is the regularization term, which can be trained for individual model. $\mathcal{L}(f(\mathcal{X}|\phi)$ measures the difference between the predicted outcome using model $f(\mathcal{X}|\phi)$ and expected outcome, which often measured using cross entropy and can also be optimized during training. 
\par 
A typical objective function used in ANN needs to be differentiable and this is because modern model training uses back-propagation method~\cite{LeCun_2015,Heaton_2017} to update the weights of each neuron in the network, which involves calculating the gradient of the objective function with respect to weights $\frac {\partial{C}} {\partial{w_{ij}}} $.